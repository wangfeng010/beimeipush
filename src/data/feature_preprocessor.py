#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç‰¹å¾é¢„å¤„ç†å™¨
ç›´æ¥ä½¿ç”¨é¡¹ç›®çš„æ“ä½œå‡½æ•°å®ç°ç‰¹å¾é¢„å¤„ç†ï¼Œå°†åŸå§‹CSVæ•°æ®è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
"""

import os
import sys
import pandas as pd
import tensorflow as tf
from typing import Dict, List, Any
from functools import partial

# å¯¼å…¥é¡¹ç›®æœ¬èº«çš„æ“ä½œå‡½æ•°
from src.preprocess.operations import OP_HUB
from src.utils.config_utils import load_feature_config


def run_one_op_pd(df: pd.DataFrame, op) -> pd.DataFrame:
    """
    æ‰§è¡Œå•ä¸ªæ“ä½œ - ä½¿ç”¨é¡¹ç›®çš„OP_HUBå®ç°
    """
    col_in = op.col_in
    col_out = op.col_out
    func_name = op.func_name
    parameters = op.func_parameters if op.func_parameters else dict()
    partial_func = partial(OP_HUB[func_name], **parameters)

    if isinstance(col_in, list):
        df[col_out] = df[col_in].apply(lambda row: partial_func(*row), axis=1)
    else:
        df[col_out] = df[col_in].apply(partial_func)
    return df


def preprocess_features(df: pd.DataFrame, feat_configs: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    ä½¿ç”¨é¡¹ç›®çš„æ“ä½œå‡½æ•°é¢„å¤„ç†ç‰¹å¾
    
    Args:
        df: è¾“å…¥DataFrame
        feat_configs: ç‰¹å¾é…ç½®åˆ—è¡¨
        
    Returns:
        å¤„ç†åçš„DataFrame
    """
    working_df = df.copy()
    
    # ä¸ºæ¯ä¸ªç‰¹å¾æ‰§è¡Œæ“ä½œé“¾
    for config in feat_configs:
        operations = config.get('operations', [])
        
        # æ‰§è¡Œæ“ä½œé“¾
        for op_dict in operations:
            # åˆ›å»ºæ“ä½œå¯¹è±¡
            from uniprocess.config import OperationConfig
            op = OperationConfig(**op_dict)
            
            # æ£€æŸ¥è¾“å…¥åˆ—æ˜¯å¦å­˜åœ¨
            if isinstance(op.col_in, list):
                missing_cols = [col for col in op.col_in if col not in working_df.columns]
            else:
                missing_cols = [] if op.col_in in working_df.columns else [op.col_in]
            
            if missing_cols:
                print(f"WARNING: ç¼ºå¤±è¾“å…¥åˆ— {missing_cols}ï¼Œè·³è¿‡æ“ä½œ {op.func_name}")
                continue
            
            # æ‰§è¡Œæ“ä½œ
            try:
                working_df = run_one_op_pd(working_df, op)
                print(f"âœ… æ‰§è¡Œæ“ä½œ: {op.col_in} --{op.func_name}--> {op.col_out}")
            except Exception as e:
                print(f"âŒ æ“ä½œå¤±è´¥: {op.func_name}, é”™è¯¯: {e}")
                continue
    
    return working_df


def apply_feature_preprocessing(dataset: tf.data.Dataset, 
                               feat_config_path: str = "config/feat.yml",
                               verbose: bool = True) -> tf.data.Dataset:
    """
    å¯¹TensorFlowæ•°æ®é›†åº”ç”¨ç‰¹å¾é¢„å¤„ç†
    
    Args:
        dataset: åŸå§‹æ•°æ®é›†
        feat_config_path: ç‰¹å¾é…ç½®æ–‡ä»¶è·¯å¾„
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        
    Returns:
        å¤„ç†åçš„æ•°æ®é›†
    """
    if verbose:
        print("ğŸ”§ ä½¿ç”¨é¡¹ç›®æ“ä½œå‡½æ•°é¢„å¤„ç†ç‰¹å¾...")
    
    # åŠ è½½ç‰¹å¾é…ç½®
    feat_configs = load_feature_config(feat_config_path)
    
    # å°†æ•°æ®é›†è½¬æ¢ä¸ºpandas DataFrameè¿›è¡Œå¤„ç†
    def process_pandas_batch(features_dict, labels_tensor):
        """ä½¿ç”¨pandaså¤„ç†æ‰¹æ¬¡æ•°æ®"""
        # è½¬æ¢ä¸ºpandas DataFrame
        batch_data = {}
        for name, tensor in features_dict.items():
            if tensor.dtype == tf.string:
                values = [item.decode('utf-8') if isinstance(item, bytes) else str(item) 
                         for item in tensor.numpy()]
            else:
                values = tensor.numpy().tolist()
            batch_data[name] = values
        
        df = pd.DataFrame(batch_data)
        
        # ä½¿ç”¨é¡¹ç›®æ“ä½œå‡½æ•°å¤„ç†
        processed_df = preprocess_features(df, feat_configs)
        
        # åˆ›å»ºå¤„ç†åçš„ç‰¹å¾å­—å…¸
        processed_features = {}
        for config in feat_configs:
            feat_name = config['feat_name']
            if feat_name in processed_df.columns:
                feat_type = config.get('feat_type', 'sparse')
                values = processed_df[feat_name].tolist()
                
                if feat_type in ['sparse', 'varlen_sparse']:
                    if feat_type == 'varlen_sparse':
                        # å¤„ç†å˜é•¿ç‰¹å¾ï¼Œç¡®ä¿æ‰€æœ‰åˆ—è¡¨é•¿åº¦ä¸€è‡´
                        max_len = max(len(v) if isinstance(v, list) else 1 for v in values)
                        padded_values = []
                        for val in values:
                            if isinstance(val, list):
                                padded = val + [0] * (max_len - len(val))
                            else:
                                padded = [int(val) if val != 'null' else 0] + [0] * (max_len - 1)
                            padded_values.append(padded[:max_len])
                        processed_features[feat_name] = tf.constant(padded_values, dtype=tf.int32)
                    else:
                        # å•å€¼ç‰¹å¾
                        int_values = [int(x) if x != 'null' else 0 for x in values]
                        processed_features[feat_name] = tf.constant(int_values, dtype=tf.int32)
                elif feat_type == 'dense':
                    float_values = [float(x) for x in values]
                    processed_features[feat_name] = tf.constant(float_values, dtype=tf.float32)
                else:
                    str_values = [str(x) for x in values]
                    processed_features[feat_name] = tf.constant(str_values, dtype=tf.string)
        
        return processed_features, labels_tensor
    
    # ç›´æ¥åœ¨eageræ¨¡å¼ä¸‹å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
    processed_batches = []
    
    if verbose:
        print("   å¼€å§‹æ‰¹é‡å¤„ç†æ•°æ®...")
    
    batch_count = 0
    for features, labels in dataset:
        try:
            processed_features, processed_labels = process_pandas_batch(features, labels)
            processed_batches.append((processed_features, processed_labels))
            batch_count += 1
            if verbose and batch_count % 10 == 0:
                print(f"   å·²å¤„ç† {batch_count} ä¸ªæ‰¹æ¬¡")
        except Exception as e:
            if verbose:
                print(f"âŒ æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
            raise e
    
    # é‡æ–°åˆ›å»ºæ•°æ®é›†
    def generator():
        for features, labels in processed_batches:
            yield features, labels
    
    # åˆ›å»ºè¾“å‡ºç­¾å
    feature_spec = {}
    for config in feat_configs:
        feat_name = config['feat_name']
        feat_type = config.get('feat_type', 'sparse')
        
        if feat_type == 'varlen_sparse':
            feature_spec[feat_name] = tf.TensorSpec(shape=(None, None), dtype=tf.int32)
        elif feat_type in ['sparse']:
            feature_spec[feat_name] = tf.TensorSpec(shape=(None,), dtype=tf.int32)
        elif feat_type == 'dense':
            feature_spec[feat_name] = tf.TensorSpec(shape=(None,), dtype=tf.float32)
        else:
            feature_spec[feat_name] = tf.TensorSpec(shape=(None,), dtype=tf.string)
    
    label_spec = tf.TensorSpec(shape=(None,), dtype=tf.int32)
    
    processed_dataset = tf.data.Dataset.from_generator(
        generator,
        output_signature=(feature_spec, label_spec)
    )
    
    if verbose:
        print(f"âœ… ç‰¹å¾é¢„å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {batch_count} ä¸ªæ‰¹æ¬¡")
    
    return processed_dataset 