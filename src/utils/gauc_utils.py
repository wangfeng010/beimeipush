#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
GAUC (Group AUC) è®¡ç®—å·¥å…· - ç®€åŒ–ç‰ˆ
"""

import os
import json
import datetime
from typing import Dict, List, Tuple, Any, Optional
from collections import defaultdict

import numpy as np
import tensorflow as tf
from sklearn.metrics import roc_auc_score


def calculate_gauc_with_original_data(
    model: tf.keras.Model,
    processed_dataset: tf.data.Dataset,
    original_dataset: tf.data.Dataset,
    min_samples_per_user: int = 2,
    max_batches: Optional[int] = None,
    verbose: bool = True
) -> Tuple[float, Dict[str, Any]]:
    """
    ä½¿ç”¨åŸå§‹æ•°æ®é›†ä¸­çš„user_idè®¡ç®—GAUC
    """
    if verbose:
        print("ğŸ” å¼€å§‹è®¡ç®—GAUC...")
    
    user_data = defaultdict(lambda: {'predictions': [], 'labels': []})
    total_samples = 0
    
    processed_iter = iter(processed_dataset)
    original_iter = iter(original_dataset)
    
    for batch_idx in range(max_batches if max_batches else 1000):
        # è·å–æ•°æ®æ‰¹æ¬¡
        processed_batch = next(processed_iter, None)
        original_batch = next(original_iter, None)
        
        if processed_batch is None or original_batch is None:
            break
            
        processed_features, processed_labels = processed_batch
        original_features, original_labels = original_batch
        
        # æ£€æŸ¥user_id
        if "user_id" not in original_features:
            raise ValueError("åŸå§‹æ•°æ®é›†ä¸­ç¼ºå°‘'user_id'å­—æ®µ")
        
        # æ¨¡å‹é¢„æµ‹
        predictions = model(processed_features, training=False)
        
        # æå–æ•°æ®
        user_ids = original_features["user_id"].numpy()
        pred_values = predictions.numpy().flatten()
        label_values = processed_labels.numpy().flatten()
        
        # æ£€æŸ¥æ•°ç»„é•¿åº¦æ˜¯å¦ä¸€è‡´
        n_users = len(user_ids)
        n_preds = len(pred_values)
        n_labels = len(label_values)
        
        if n_users != n_preds or n_users != n_labels:
            if verbose:
                print(f"âš ï¸ æ‰¹æ¬¡ {batch_idx} æ•°ç»„é•¿åº¦ä¸åŒ¹é…: users={n_users}, preds={n_preds}, labels={n_labels}")
            # å–æœ€å°é•¿åº¦ç¡®ä¿ç´¢å¼•å®‰å…¨
            min_length = min(n_users, n_preds, n_labels)
            user_ids = user_ids[:min_length]
            pred_values = pred_values[:min_length]
            label_values = label_values[:min_length]
        
        # æŒ‰ç”¨æˆ·åˆ†ç»„
        for i in range(len(user_ids)):
            user_id = user_ids[i]
            user_id_str = user_id.decode('utf-8') if isinstance(user_id, bytes) else str(user_id)
            user_data[user_id_str]['predictions'].append(float(pred_values[i]))
            user_data[user_id_str]['labels'].append(int(label_values[i]))
        
        total_samples += len(user_ids)
    
    return _calculate_gauc_from_user_data(user_data, min_samples_per_user, total_samples, verbose)


def _calculate_gauc_from_user_data(
    user_data: Dict[str, Dict[str, List]],
    min_samples_per_user: int,
    total_samples: int,
    verbose: bool = True
) -> Tuple[float, Dict[str, Any]]:
    """ä»ç”¨æˆ·æ•°æ®è®¡ç®—GAUC"""
    
    # è¿‡æ»¤æœ‰æ•ˆç”¨æˆ·
    valid_users = {}
    for user_id, data in user_data.items():
        if len(data['predictions']) >= min_samples_per_user:
            unique_labels = set(data['labels'])
            if len(unique_labels) > 1:  # éœ€è¦æ­£è´Ÿæ ·æœ¬
                valid_users[user_id] = data
    
    if len(valid_users) == 0:
        return 0.0, {
            'total_users': len(user_data),
            'valid_users': 0,
            'total_samples': total_samples,
            'error': 'no_valid_users'
        }
    
    # è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„AUC
    user_aucs = []
    for user_id, data in valid_users.items():
        if len(set(data['labels'])) > 1:  # ç¡®ä¿æœ‰æ­£è´Ÿæ ·æœ¬
            user_auc = roc_auc_score(data['labels'], data['predictions'])
            user_aucs.append(user_auc)
    
    if len(user_aucs) == 0:
        return 0.0, {
            'total_users': len(user_data),
            'valid_users': len(valid_users),
            'total_samples': total_samples,
            'error': 'auc_calculation_failed'
        }
    
    # è®¡ç®—GAUCï¼ˆç®€å•å¹³å‡ï¼‰
    gauc_score = np.mean(user_aucs)
    
    gauc_info = {
        'total_users': len(user_data),
        'valid_users': len(user_aucs),
        'total_samples': total_samples,
        'user_auc_mean': float(np.mean(user_aucs)),
        'user_auc_std': float(np.std(user_aucs))
    }
    
    if verbose:
        print(f"âœ… GAUC: {gauc_score:.4f} (æœ‰æ•ˆç”¨æˆ·: {len(user_aucs)})")
    
    return gauc_score, gauc_info


def calculate_gauc(
    model: tf.keras.Model,
    dataset: tf.data.Dataset,
    min_samples_per_user: int = 2,
    max_batches: Optional[int] = None,
    verbose: bool = True
) -> Tuple[float, Dict[str, Any]]:
    """è®¡ç®—GAUCï¼ˆæ ‡å‡†ç‰ˆæœ¬ï¼‰"""
    if verbose:
        print("ğŸ” å¼€å§‹è®¡ç®—GAUC...")
    
    user_data = defaultdict(lambda: {'predictions': [], 'labels': []})
    total_samples = 0
    
    for batch_idx, (features, labels) in enumerate(dataset):
        if max_batches and batch_idx >= max_batches:
            break
            
        if "user_id" not in features:
            raise ValueError("æ•°æ®é›†ä¸­ç¼ºå°‘'user_id'å­—æ®µ")
        
        predictions = model(features, training=False)
        user_ids = features["user_id"].numpy()
        pred_values = predictions.numpy().flatten()
        label_values = labels.numpy().flatten()
        
        # æ£€æŸ¥æ•°ç»„é•¿åº¦æ˜¯å¦ä¸€è‡´
        n_users = len(user_ids)
        n_preds = len(pred_values)
        n_labels = len(label_values)
        
        if n_users != n_preds or n_users != n_labels:
            if verbose:
                print(f"âš ï¸ æ‰¹æ¬¡ {batch_idx} æ•°ç»„é•¿åº¦ä¸åŒ¹é…: users={n_users}, preds={n_preds}, labels={n_labels}")
            # å–æœ€å°é•¿åº¦ç¡®ä¿ç´¢å¼•å®‰å…¨
            min_length = min(n_users, n_preds, n_labels)
            user_ids = user_ids[:min_length]
            pred_values = pred_values[:min_length]
            label_values = label_values[:min_length]
        
        # æŒ‰ç”¨æˆ·åˆ†ç»„
        for i in range(len(user_ids)):
            user_id = user_ids[i]
            user_id_str = user_id.decode('utf-8') if isinstance(user_id, bytes) else str(user_id)
            user_data[user_id_str]['predictions'].append(float(pred_values[i]))
            user_data[user_id_str]['labels'].append(int(label_values[i]))
        
        total_samples += len(user_ids)
    
    return _calculate_gauc_from_user_data(user_data, min_samples_per_user, total_samples, verbose)


def save_gauc_results(
    gauc_score: float,
    gauc_info: Dict[str, Any],
    output_dir: str = "logs"
) -> str:
    """ä¿å­˜GAUCç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"gauc_results_{timestamp}.json"
    filepath = os.path.join(output_dir, filename)
    
    results = {
        'timestamp': timestamp,
        'gauc_score': gauc_score,
        'gauc_info': gauc_info
    }
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    return filepath


def compare_auc_gauc(
    auc_score: float,
    gauc_score: float,
    verbose: bool = True
) -> Dict[str, Any]:
    """å¯¹æ¯”AUCå’ŒGAUC"""
    auc_gauc_diff = auc_score - gauc_score
    relative_diff = (auc_gauc_diff / auc_score) * 100 if auc_score > 0 else 0
    
    # ç®€åŒ–çš„è§£è¯»
    if abs(relative_diff) < 1:
        interpretation = "AUCå’ŒGAUCåŸºæœ¬ä¸€è‡´"
    elif auc_gauc_diff > 0:
        if relative_diff > 10:
            interpretation = "AUCæ˜æ˜¾é«˜äºGAUCï¼Œå¯èƒ½å­˜åœ¨ç”¨æˆ·åå·®"
        else:
            interpretation = "AUCé«˜äºGAUCï¼Œå±äºæ­£å¸¸èŒƒå›´"
    else:
        interpretation = "GAUCé«˜äºAUC"
    
    comparison = {
        'auc_score': float(auc_score),
        'gauc_score': float(gauc_score),
        'absolute_difference': float(auc_gauc_diff),
        'relative_difference_percent': float(relative_diff),
        'interpretation': interpretation
    }
    
    if verbose:
        print(f"ğŸ“Š AUC: {auc_score:.4f}, GAUC: {gauc_score:.4f}")
        print(f"   å·®å¼‚: {auc_gauc_diff:.4f} ({relative_diff:.1f}%)")
        print(f"   è§£è¯»: {interpretation}")
    
    return comparison


def validate_gauc_calculation(
    model: tf.keras.Model,
    small_dataset: tf.data.Dataset,
    verbose: bool = True
) -> bool:
    """éªŒè¯GAUCè®¡ç®—æ­£ç¡®æ€§"""
    gauc_score, gauc_info = calculate_gauc(
        model, small_dataset, min_samples_per_user=1, verbose=False
    )
    
    # åŸºæœ¬æ£€æŸ¥
    valid = (
        0 <= gauc_score <= 1 and
        gauc_info.get('valid_users', 0) > 0 and
        gauc_info.get('total_samples', 0) > 0
    )
    
    if verbose:
        print(f"GAUCéªŒè¯: {'âœ… é€šè¿‡' if valid else 'âŒ å¤±è´¥'}")
    
    return valid 