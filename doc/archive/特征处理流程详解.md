# 基于UniProcess框架的特征处理流程详解

本文档基于提供的配置文件 `config.yml` 和训练数据，详细展示每个特征的处理流程。

## 原始数据格式

训练数据的列结构：
```
user_id,create_time,log_type,watchlists,holdings,country,prefer_bid,user_propernoun,push_title,push_content,item_code,item_tags,submit_type
```

### 示例数据行：
```
1800001088,2025-05-31 08:39:07,PR,,,Germany,,germany#3.06|mid-america#1.02,Ainvest Newswire,Hims & Hers Health Lays Off 4% of Staff Amid Strategy Shift,"[{""market"":""169"",""score"":0,""code"":""HIMS"",""tagId"":""U000012934"",""name"":""Hims & Hers Health"",""type"":0,""parentId"":""US_ROBOT0f37d7fd3fca6a41""}]","[{""score"":0.7803922295570374,""tagId"":""51510"",""name"":""us_high_importance"",""type"":4,""parentId"":""US_ROBOT0f37d7fd3fca6a41""}]",autoFlash
```

---

## 特征处理详解

### 1. 时间特征：hour

**目标：** 从时间戳中提取小时信息  
**输入列：** `create_time`  
**最终特征：** `hour`  
**特征类型：** sparse (稀疏特征)  
**词汇表大小：** 24 (0-23小时)

#### 处理步骤：

**步骤1：fillna（缺失值填充）**
```yaml
col_in: create_time
col_out: create_time
func_name: fillna
func_parameters:
  na_value: "2024-08-02 00:16:34"
```

- **输入示例：** `"2025-05-31 08:39:07"` 或 `null`
- **输出示例：** `"2025-05-31 08:39:07"` (如果是null则填充为 `"2024-08-02 00:16:34"`)

**步骤2：to_hour（提取小时）**
```yaml
col_in: create_time
col_out: hour
func_name: to_hour
func_parameters: {}
```

- **输入示例：** `"2025-05-31 08:39:07"`
- **处理逻辑：** 使用多种日期格式尝试解析，提取小时部分
- **输出示例：** `8` (对应上午8点)

---

### 2. 时间特征：weekday

**目标：** 从时间戳中提取星期几信息  
**输入列：** `create_time`  
**最终特征：** `weekday`  
**特征类型：** sparse  
**词汇表大小：** 7 (0-6，0表示周一)

#### 处理步骤：

**步骤1：to_weekday（提取星期几）**
```yaml
col_in: create_time
col_out: weekday
func_name: to_weekday
func_parameters: {}
```

- **输入示例：** `"2025-05-31 08:39:07"`
- **处理逻辑：** 解析日期并返回星期几（0=周一，6=周日）
- **输出示例：** `5` (2025-05-31是周六)

---

### 3. 用户关注股票代码：user_watch_stk_code_hash

**目标：** 处理用户关注列表，提取股票代码并进行哈希编码  
**输入列：** `watchlists`  
**最终特征：** `user_watch_stk_code_hash`  
**特征类型：** varlen_sparse (变长稀疏特征)  
**词汇表大小：** 10000

#### 处理步骤：

**步骤1：fillna（缺失值填充）**
```yaml
col_in: watchlists
col_out: watchlists
func_name: fillna
func_parameters:
  na_value: "null_0 & null_0"
```

- **输入示例：** `"CLRO_186 & ETRN_169 & GOOGL_185 & TSLA_185 & AAPL_185 & AMZN_185 & BANL_186"` 或空值
- **输出示例：** `"CLRO_186 & ETRN_169 & GOOGL_185 & TSLA_185 & AAPL_185 & AMZN_185 & BANL_186"`

**步骤2：split（分割字符串）**
```yaml
col_in: watchlists
col_out: watchlists
func_name: split
func_parameters:
  sep: " & "
```

- **输入示例：** `"CLRO_186 & ETRN_169 & GOOGL_185 & TSLA_185 & AAPL_185 & AMZN_185 & BANL_186"`
- **输出示例：** `["CLRO_186", "ETRN_169", "GOOGL_185", "TSLA_185", "AAPL_185", "AMZN_185", "BANL_186"]`

**步骤3：seperation（二次分割）**
```yaml
col_in: watchlists
col_out: watchlists
func_name: seperation
func_parameters:
  sep: "_"
```

- **输入示例：** `["CLRO_186", "ETRN_169", "GOOGL_185"]`
- **输出示例：** `[["CLRO", "186"], ["ETRN", "169"], ["GOOGL", "185"]]`

**步骤4：list_get（提取股票代码）**
```yaml
col_in: watchlists
col_out: user_watch_stk_code
func_name: list_get
func_parameters:
  item_index: 0
```

- **输入示例：** `[["CLRO", "186"], ["ETRN", "169"], ["GOOGL", "185"]]`
- **输出示例：** `["CLRO", "ETRN", "GOOGL", "TSLA", "AAPL", "AMZN", "BANL"]`

**步骤5：remove_items（移除特定股票）**
```yaml
col_in: user_watch_stk_code
col_out: user_watch_stk_code
func_name: remove_items
func_parameters:
  target_values: ["AAPL", "AMZN", "GOOGL", "TSLA"]
```

- **输入示例：** `["CLRO", "ETRN", "GOOGL", "TSLA", "AAPL", "AMZN", "BANL"]`
- **输出示例：** `["CLRO", "ETRN", "BANL"]` (移除了GOOGL, TSLA, AAPL, AMZN)

**步骤6：padding（填充到固定长度）**
```yaml
col_in: user_watch_stk_code
col_out: user_watch_stk_code
func_name: padding
func_parameters:
  max_len: 5
  pad_value: "null"
```

- **输入示例：** `["CLRO", "ETRN", "BANL"]`
- **输出示例：** `["CLRO", "ETRN", "BANL", "null", "null"]`

**步骤7：list_hash（哈希编码）**
```yaml
col_in: user_watch_stk_code
col_out: user_watch_stk_code_hash
func_name: list_hash
func_parameters:
  vocabulary_size: 10000
```

- **输入示例：** `["CLRO", "ETRN", "BANL", "null", "null"]`
- **输出示例：** `[1234, 5678, 9012, 0, 0]` (通过哈希函数映射到0-9999的整数)

---

### 4. 国家特征：country_hash

**目标：** 对用户国家进行哈希编码  
**输入列：** `country`  
**最终特征：** `country_hash`  
**特征类型：** sparse  
**词汇表大小：** 200

#### 处理步骤：

**步骤1：fillna（缺失值填充）**
```yaml
col_in: country
col_out: country
func_name: fillna
func_parameters:
  na_value: "null"
```

- **输入示例：** `"United States"` 或 空值
- **输出示例：** `"United States"`

**步骤2：str_hash（字符串哈希）**
```yaml
col_in: country
col_out: country_hash
func_name: str_hash
func_parameters:
  vocabulary_size: 200
```

- **输入示例：** `"United States"`
- **输出示例：** `123` (通过哈希函数映射到0-199的整数)

---

### 5. 用户偏好股票：prefer_bid_code_hash

**目标：** 处理用户偏好股票数据  
**输入列：** `prefer_bid`  
**最终特征：** `prefer_bid_code_hash`  
**特征类型：** varlen_sparse  
**词汇表大小：** 10000

#### 处理步骤：

**步骤1：fillna**
- **输入示例：** `"beam#1.02|chennai airport#1.02|tesla#3.06"` 或空值
- **输出示例：** `"beam#1.02|chennai airport#1.02|tesla#3.06"`

**步骤2：split**
- **输入示例：** `"beam#1.02|chennai airport#1.02|tesla#3.06"`
- **输出示例：** `["beam#1.02", "chennai airport#1.02", "tesla#3.06"]`

**步骤3：seperation**
- **输入示例：** `["beam#1.02", "chennai airport#1.02", "tesla#3.06"]`
- **输出示例：** `[["beam", "1.02"], ["chennai airport", "1.02"], ["tesla", "3.06"]]`

**步骤4：list_get**
- **输入示例：** `[["beam", "1.02"], ["chennai airport", "1.02"], ["tesla", "3.06"]]`
- **输出示例：** `["beam", "chennai airport", "tesla"]`

**步骤5：padding**
- **输入示例：** `["beam", "chennai airport", "tesla"]`
- **输出示例：** `["beam", "chennai airport", "tesla", "null", "null"]`

**步骤6：list_hash**
- **输入示例：** `["beam", "chennai airport", "tesla", "null", "null"]`
- **输出示例：** `[2341, 5672, 8903, 0, 0]`

---

### 6. 用户持仓：hold_bid_code_hash

**目标：** 处理用户持仓数据  
**输入列：** `holdings`  
**最终特征：** `hold_bid_code_hash`  
**特征类型：** varlen_sparse  
**词汇表大小：** 10000

#### 处理步骤：

**步骤1到6：** 与prefer_bid_code_hash类似，但分隔符不同

- **原始输入：** `"JD,185|BAC,169|TSLA,185"`
- **最终输出：** `[1234, 5678, 9012, 0, 0]` (哈希后的持仓股票代码)

---

### 7. 用户专有词汇：user_propernoun_hash

**目标：** 处理用户的专有名词偏好  
**输入列：** `user_propernoun`  
**最终特征：** `user_propernoun_hash`  
**特征类型：** varlen_sparse  
**词汇表大小：** 10000

#### 处理步骤：

与prefer_bid类似的处理流程：

- **原始输入：** `"germany#3.06|mid-america#1.02"`
- **最终输出：** `[3456, 7890, 0, 0, 0]` (哈希后的专有名词)

---

### 8. 推送标题：push_title_hash

**目标：** 对推送标题进行哈希编码  
**输入列：** `push_title`  
**最终特征：** `push_title_hash`  
**特征类型：** sparse  
**词汇表大小：** 8

#### 处理步骤：

**步骤1：fillna**
- **输入示例：** `"Breaking News"`
- **输出示例：** `"Breaking News"`

**步骤2：str_hash**
- **输入示例：** `"Breaking News"`
- **输出示例：** `3` (映射到0-7的整数)

---

### 9. 内容长度：title_len

**目标：** 计算推送内容的词数长度  
**输入列：** `push_content`  
**最终特征：** `title_len`  
**特征类型：** sparse  
**词汇表大小：** 32

#### 处理步骤：

**步骤1：fillna**
- **输入示例：** `"Hims & Hers Health Lays Off 4% of Staff Amid Strategy Shift"`

**步骤2：split（按空格分割）**
- **输入示例：** `"Hims & Hers Health Lays Off 4% of Staff Amid Strategy Shift"`
- **输出示例：** `["Hims", "&", "Hers", "Health", "Lays", "Off", "4%", "of", "Staff", "Amid", "Strategy", "Shift"]`

**步骤3：list_len（计算长度）**
- **输入示例：** `["Hims", "&", "Hers", "Health", "Lays", "Off", "4%", "of", "Staff", "Amid", "Strategy", "Shift"]`
- **输出示例：** `12`

**步骤4：int_max（限制最大值）**
- **输入示例：** `12`
- **输出示例：** `12` (如果超过31则限制为31)

---

### 10. 推送商品代码：item_code_hash

**目标：** 从JSON格式的商品信息中提取股票代码  
**输入列：** `item_code`  
**最终特征：** `item_code_hash`  
**特征类型：** varlen_sparse  
**词汇表大小：** 10000

#### 处理步骤：

**步骤1：fillna**
- **输入示例：** `'[{"market":"169","score":0,"code":"HIMS","tagId":"U000012934","name":"Hims & Hers Health","type":0,"parentId":"US_ROBOT0f37d7fd3fca6a41"}]'`

**步骤2：json_object_to_list（提取JSON中的code字段）**
```yaml
col_in: item_code
col_out: item_code
func_name: json_object_to_list
func_parameters:
  key: "code"
```

- **输入示例：** JSON字符串
- **输出示例：** `["HIMS", "NVO"]` (提取所有对象的code字段)

**步骤3：padding**
- **输入示例：** `["HIMS", "NVO"]`
- **输出示例：** `["HIMS", "NVO", "null", "null", "null"]`

**步骤4：list_hash**
- **输入示例：** `["HIMS", "NVO", "null", "null", "null"]`
- **输出示例：** `[4567, 8901, 0, 0, 0]`

---

### 11. 提交类型：submit_type_hash

**目标：** 对提交类型进行哈希编码  
**输入列：** `submit_type`  
**最终特征：** `submit_type_hash`  
**特征类型：** sparse  
**词汇表大小：** 10

#### 处理步骤：

- **输入示例：** `"autoFlash"`
- **输出示例：** `7` (哈希映射结果)

---

### 12. 标签ID：tag_id_hash

**目标：** 从JSON格式的标签信息中提取标签ID  
**输入列：** `item_tags`  
**最终特征：** `tag_id_hash`  
**特征类型：** varlen_sparse  
**词汇表大小：** 10000

#### 处理步骤：

类似item_code_hash的处理，但提取"tagId"字段：

- **原始输入：** JSON标签信息
- **最终输出：** `[1234, 5678, 9012]` (哈希后的标签ID)

---

## 特征交叉 (Interactions)

### 1. preder_bid_cross

**目标：** 检查商品代码与用户偏好是否有交集  
**输入：** `[item_code, prefer_bid_code]`  
**输出：** `1` (有交集) 或 `0` (无交集)

### 2. watch_bid_cross

**目标：** 检查商品代码与用户关注列表是否有交集  
**输入：** `[item_code, user_watch_stk_code]`  
**输出：** `1` (有交集) 或 `0` (无交集)

### 3. hold_bid_cross

**目标：** 检查商品代码与用户持仓是否有交集  
**输入：** `[item_code, hold_bid_code]`  
**输出：** `1` (有交集) 或 `0` (无交集)

---

## 标签处理 (Label Processing)

### log_type

**目标：** 将字符串标签转换为数值  
**输入列：** `log_type`  
**最终特征：** `log_type`

#### 处理步骤：

**步骤1：fillna**
- **输入示例：** `"PR"` 或 `"PC"`
- **输出示例：** `"PR"`

**步骤2：map_to_int（映射为整数）**
```yaml
func_parameters:
  map_dict:
    PR: 0
    PC: 1
  default_code: 0
```

- **输入示例：** `"PR"`
- **输出示例：** `0`
- **输入示例：** `"PC"`
- **输出示例：** `1`

---

## 总结

整个特征处理流程展现了一个完整的推荐系统数据预处理管道：

1. **时间特征**：提取时间相关信息（小时、星期几）
2. **用户画像特征**：处理用户的关注列表、持仓、偏好等多维度信息
3. **内容特征**：处理推送内容的标题、长度、标签等
4. **商品特征**：提取推送中涉及的股票代码
5. **交叉特征**：计算用户特征与商品特征的交互关系
6. **标签处理**：将目标变量转换为模型可用格式

每个特征都经过了精心设计的多步骤处理，确保数据质量和特征有效性。 