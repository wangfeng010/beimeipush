{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 17:28:35.361622: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-01-10 17:28:35.361661: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    \"user_id\",\n",
    "    \"prod_buy_cnt\",\n",
    "    \"prod_pay_amt\",\n",
    "    \"prod_permission_days\",\n",
    "    \"adm_click_cnt\",\n",
    "    \"refuse_call_num_7d\",\n",
    "    \"k002602\",\n",
    "    \"k001565\",\n",
    "    \"k000431\",\n",
    "    \"k5142\",\n",
    "    \"k5137\",\n",
    "    \"k1380\",\n",
    "    \"k001336\",\n",
    "]\n",
    "label_columns = [\n",
    "    \"is_called\",\n",
    "    \"is_addv\",\n",
    "    \"is_paid\",\n",
    "]\n",
    "# 定义列名（根据 CSV 文件的列）\n",
    "column_names = feature_columns + label_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV加载方式\n",
    "1.  单文件：`file_pattern = \"/read-only/sample/folder_6661/sample_6661_1/20241014.txt\"`\n",
    "2.  文件列表：`file_pattern = \"/read-only/sample/folder_6661/sample_6661_1/*.txt\"`\n",
    "3.  通配符模式：`file_pattern = [\"data1.csv\", \"data2.csv\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用方式没有区别\n",
    "file_pattern = \"/read-only/sample/folder_6661/sample_6661_1/20241014.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义列的数据类型：手动指定\n",
    "column_defaults = [tf.string] * len(feature_columns) + [tf.int32] * len(\n",
    "    label_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集构建\n",
    "\n",
    "- `make_csv_dataset`仅支持单列作为label\n",
    "- 多列需要特殊处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: user_id (32,) <dtype: 'string'>\n",
      "Features: prod_buy_cnt (32,) <dtype: 'string'>\n",
      "Features: prod_pay_amt (32,) <dtype: 'string'>\n",
      "Features: prod_permission_days (32,) <dtype: 'string'>\n",
      "Features: adm_click_cnt (32,) <dtype: 'string'>\n",
      "Features: refuse_call_num_7d (32,) <dtype: 'string'>\n",
      "Features: k002602 (32,) <dtype: 'string'>\n",
      "Features: k001565 (32,) <dtype: 'string'>\n",
      "Features: k000431 (32,) <dtype: 'string'>\n",
      "Features: k5142 (32,) <dtype: 'string'>\n",
      "Features: k5137 (32,) <dtype: 'string'>\n",
      "Features: k1380 (32,) <dtype: 'string'>\n",
      "Features: k001336 (32,) <dtype: 'string'>\n",
      "Features: is_addv (32,) <dtype: 'int32'>\n",
      "Features: is_paid (32,) <dtype: 'int32'>\n",
      "Labels: (32,) <dtype: 'int32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 17:28:39.141471: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-01-10 17:28:39.142753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-01-10 17:28:39.183997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.835GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2025-01-10 17:28:39.184820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:82:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.835GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2025-01-10 17:28:39.185235: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-01-10 17:28:39.185546: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-10 17:28:39.185944: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-10 17:28:39.188095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-01-10 17:28:39.188631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-01-10 17:28:39.190949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-01-10 17:28:39.191296: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2025-01-10 17:28:39.191587: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2025-01-10 17:28:39.191599: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-01-10 17:28:39.196069: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-01-10 17:28:39.196097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-01-10 17:28:39.196105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2025-01-10 17:28:39.342153: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-01-10 17:28:39.344590: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2499995000 Hz\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern,\n",
    "    batch_size=batch_size,  # 每次读取的批次大小\n",
    "    column_names=column_names,  # 列名\n",
    "    field_delim=\"\\t\",\n",
    "    column_defaults=column_defaults,  # 列的数据类型 (不加会自动推断，容易出错)\n",
    "    label_name=\"is_called\",  # 标签列名( 仅支持单个标签)\n",
    "    num_epochs=1,  # 数据重复次数（None 表示无限重复）\n",
    "    shuffle=True,  # 是否打乱数据\n",
    "    shuffle_buffer_size=1000,  # 打乱缓冲区大小\n",
    "    ignore_errors=True,  # 忽略解析错误\n",
    ")\n",
    "\n",
    "for batch in dataset.take(1):\n",
    "    feat = batch[0]\n",
    "    label = batch[1]\n",
    "    for k, v in feat.items():\n",
    "        print(\"Features:\", k, v.shape, v.dtype)\n",
    "\n",
    "    print(\"Labels:\", label.shape, label.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除某一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: prod_buy_cnt (32,) <dtype: 'string'>\n",
      "Features: prod_pay_amt (32,) <dtype: 'string'>\n",
      "Features: prod_permission_days (32,) <dtype: 'string'>\n",
      "Features: adm_click_cnt (32,) <dtype: 'string'>\n",
      "Features: refuse_call_num_7d (32,) <dtype: 'string'>\n",
      "Features: k002602 (32,) <dtype: 'string'>\n",
      "Features: k001565 (32,) <dtype: 'string'>\n",
      "Features: k000431 (32,) <dtype: 'string'>\n",
      "Features: k5142 (32,) <dtype: 'string'>\n",
      "Features: k5137 (32,) <dtype: 'string'>\n",
      "Features: k1380 (32,) <dtype: 'string'>\n",
      "Features: k001336 (32,) <dtype: 'string'>\n",
      "Features: is_addv (32,) <dtype: 'int32'>\n",
      "Features: is_paid (32,) <dtype: 'int32'>\n",
      "Labels: (32,) <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern,\n",
    "    batch_size=batch_size,  # 每次读取的批次大小\n",
    "    column_names=column_names,  # 列名\n",
    "    field_delim=\"\\t\",\n",
    "    column_defaults=column_defaults,  # 列的数据类型 (不加会自动推断，容易出错)\n",
    "    label_name=\"is_called\",  # 标签列名( 仅支持单个标签)\n",
    "    num_epochs=1,  # 数据重复次数（None 表示无限重复）\n",
    "    shuffle=True,  # 是否打乱数据\n",
    "    shuffle_buffer_size=1000,  # 打乱缓冲区大小\n",
    "    ignore_errors=True,  # 忽略解析错误\n",
    ")\n",
    "\n",
    "def drop_columns(features:dict, labels, drop_columns):\n",
    "    for col in drop_columns:\n",
    "        features.pop(col, None )\n",
    "    return features, labels\n",
    "drop_columns_with_name = partial(\n",
    "    drop_columns, drop_columns=['user_id']\n",
    ")\n",
    "dataset = dataset.map(lambda x, y: drop_columns_with_name(x, y))\n",
    "\n",
    "\n",
    "for batch in dataset.take(1):\n",
    "    feat = batch[0]\n",
    "    label = batch[1]\n",
    "    for k, v in feat.items():\n",
    "        print(\"Features:\", k, v.shape, v.dtype)\n",
    "\n",
    "    print(\"Labels:\", label.shape, label.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多列作为label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: user_id (32,) <dtype: 'string'>\n",
      "Features: prod_buy_cnt (32,) <dtype: 'string'>\n",
      "Features: prod_pay_amt (32,) <dtype: 'string'>\n",
      "Features: prod_permission_days (32,) <dtype: 'string'>\n",
      "Features: adm_click_cnt (32,) <dtype: 'string'>\n",
      "Features: refuse_call_num_7d (32,) <dtype: 'string'>\n",
      "Features: k002602 (32,) <dtype: 'string'>\n",
      "Features: k001565 (32,) <dtype: 'string'>\n",
      "Features: k000431 (32,) <dtype: 'string'>\n",
      "Features: k5142 (32,) <dtype: 'string'>\n",
      "Features: k5137 (32,) <dtype: 'string'>\n",
      "Features: k1380 (32,) <dtype: 'string'>\n",
      "Features: k001336 (32,) <dtype: 'string'>\n",
      "Labels: is_called (32,) <dtype: 'int32'>\n",
      "Labels: is_addv (32,) <dtype: 'int32'>\n",
      "Labels: is_paid (32,) <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern,\n",
    "    batch_size=batch_size,  # 每次读取的批次大小\n",
    "    column_names=column_names,  # 列名\n",
    "    field_delim=\"\\t\",\n",
    "    column_defaults=column_defaults,  # 列的数据类型 (不加会自动推断，容易出错)\n",
    "    # label_name=\"is_called\",  # 标签列名( 仅支持单个标签)\n",
    "    num_epochs=1,  # 数据重复次数（None 表示无限重复）\n",
    "    shuffle=True,  # 是否打乱数据\n",
    "    shuffle_buffer_size=1000,  # 打乱缓冲区大小\n",
    "    ignore_errors=True,  # 忽略解析错误\n",
    ")    \n",
    "def extract_multi_labels(features, label_columns):\n",
    "        feat = {k: v for k, v in features.items() if k not in label_columns}\n",
    "        label = {k: v for k, v in features.items() if k in label_columns}\n",
    "        return feat, label\n",
    "\n",
    "\n",
    "extract_multi_labels_with_name = partial(\n",
    "    extract_multi_labels, label_columns=label_columns\n",
    ")\n",
    "dataset = dataset.map(lambda x: extract_multi_labels_with_name(x))\n",
    "\n",
    "\n",
    "for batch in dataset.take(1):\n",
    "    feat = batch[0]\n",
    "    label = batch[1]\n",
    "    for k, v in feat.items():\n",
    "        print(\"Features:\", k, v.shape, v.dtype)\n",
    "    for k, v in label.items():\n",
    "        print(\"Labels:\", k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集拆分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 48288\n",
      "Validation dataset size: 320\n"
     ]
    }
   ],
   "source": [
    "# 定义验证集大小\n",
    "validation_size = 10  # 直接指定验证集大小：10 x batch_size 行数据\n",
    "\n",
    "# 拆分数据集\n",
    "validation_dataset = dataset.take(\n",
    "    validation_size\n",
    ")  # 取前 validation_size 条数据作为验证集\n",
    "train_dataset = dataset.skip(\n",
    "    validation_size\n",
    ")  # 跳过前 validation_size 条数据作为训练集\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"Train dataset size: {sum(1 for _ in train_dataset) * batch_size}\")\n",
    "print(f\"Validation dataset size: {sum(1 for _ in validation_dataset) * batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
