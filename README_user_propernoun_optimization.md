# User_propernoun ç‰¹å¾ä¼˜åŒ–å®æ–½æ–¹æ¡ˆ

## ğŸ“‹ é¡¹ç›®èƒŒæ™¯

é€šè¿‡æ·±åº¦æ•°æ®åˆ†æå‘ç°ï¼Œ`user_propernoun` ç‰¹å¾æ˜¯æ¨é€é€šçŸ¥CTRé¢„æµ‹æ¨¡å‹ä¸­æœ€é‡è¦çš„ç‰¹å¾ï¼ˆé‡è¦æ€§æƒé‡0.197ï¼‰ï¼Œä½†å­˜åœ¨ä¸¥é‡çš„å…¬å¹³æ€§å’Œæ•°æ®æ³„éœ²é—®é¢˜ã€‚æœ¬æ–‡æ¡£æä¾›äº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ” é—®é¢˜åˆ†ææ€»ç»“

### å…³é”®å‘ç°

**æ•°æ®ç»Ÿè®¡**ï¼š
- æœ‰ `user_propernoun` çš„ç”¨æˆ·ç‚¹å‡»ç‡ï¼š**38.55%**
- æ—  `user_propernoun` çš„ç”¨æˆ·ç‚¹å‡»ç‡ï¼š**3.95%**  
- ç‚¹å‡»ç‡å·®å¼‚ï¼š**876å€æå‡**

**é—®é¢˜æ ¹æº**ï¼š
1. **éšæ€§æ•°æ®æ³„éœ²**ï¼š`user_propernoun` é—´æ¥ç¼–ç äº†ç”¨æˆ·æ´»è·ƒåº¦
2. **ä¸å…¬å¹³å¡«å……**ï¼šç¼ºå¤±å€¼ç»Ÿä¸€å¡«å……ä¸ºé›¶å‘é‡ï¼Œé€ æˆäººä¸ºçš„äºŒå…ƒåˆ†ç±»è¾¹ç•Œ
3. **è¯­ä¹‰åŒ¹é…è´¨é‡å·®**ï¼š71.3%çš„å®ä½“åŒ¹é…æ˜¯è¯¯åŒ¹é…ï¼ˆå¦‚"us"åŒ¹é…åˆ°"Musk"ï¼‰

### ä¸‰é‡æ•ˆåº”åˆ†è§£

```
ğŸ“Š æ•ˆåº”åˆ†è§£ï¼š
â”œâ”€â”€ 75% æ´»è·ƒç”¨æˆ·è¯†åˆ«æ•ˆåº”ï¼ˆè®°å¿†æ¨¡å¼ï¼‰
â”‚   â””â”€â”€ æœ‰propernoun = å¹³å°æ´»è·ƒç”¨æˆ· â†’ é«˜ç‚¹å‡»å€¾å‘
â”œâ”€â”€ 25% è¯­ä¹‰åŒ¹é…æ•ˆåº”ï¼ˆçœŸå®ä»·å€¼ï¼‰  
â”‚   â””â”€â”€ Chinaç”¨æˆ·å¯¹Chinaå†…å®¹ï¼š74.07% vs 46.92%
â””â”€â”€ æ£€æµ‹è¯¯å·®ï¼ˆ71.3%è¯¯åŒ¹é…ç‡ï¼‰
```

## ğŸ¯ è§£å†³æ–¹æ¡ˆï¼šæ”¹è¿›Embeddingå¡«å……ç­–ç•¥

### æ ¸å¿ƒæ€è·¯

**é—®é¢˜æœ¬è´¨**ï¼šå½“å‰é›¶å‘é‡å¡«å……é€ æˆäº†æ˜æ˜¾çš„"æœ‰æ— propernoun"äºŒå…ƒåˆ†ç±»è¾¹ç•Œ

**è§£å†³æ–¹æ¡ˆ**ï¼šç”¨**å¹³å‡å€¼+å™ªéŸ³**çš„æ–¹å¼å¡«å……ç¼ºå¤±å€¼ï¼Œè®©æ¨¡å‹æ›´å¤šä¾èµ–è¯­ä¹‰åŒ¹é…è€Œéæ´»è·ƒåº¦è¯†åˆ«

### å¡«å……ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥ | æè¿° | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|------|
| **é›¶å‘é‡**ï¼ˆå½“å‰ï¼‰ | `[0,0,...,0]` | ç®€å•æ˜ç¡® | ä¸¥é‡æ•°æ®æ³„éœ²ï¼Œä¸å…¬å¹³ |
| éšæœºå‘é‡ | `N(0, 0.1)` | å®Œå…¨æ‰“ç ´è¾¹ç•Œ | æ— è¯­ä¹‰å«ä¹‰ï¼Œä¸ç¨³å®š |
| å¹³å‡å€¼ | `mean(all_embeddings)` | è¯­ä¹‰åˆç† | æ‰€æœ‰äººä»ç›¸åŒ |
| **å¹³å‡å€¼+å™ªéŸ³**ï¼ˆæ¨èï¼‰ | `mean + N(0, 0.1Ã—std)` | **å¹³è¡¡è¯­ä¹‰æ€§å’Œå¤šæ ·æ€§** | éœ€è¦è°ƒå‚ |

## ğŸ›  å®æ–½æ–¹æ¡ˆ

### ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºæ”¹è¿›çš„å¤„ç†å™¨

#### 1. åˆ›å»ºæ–°çš„å¡«å……å¤„ç†å™¨

åœ¨ `src/models/deep/processors/` ç›®å½•ä¸‹åˆ›å»º `improved_filling.py`ï¼š

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import tensorflow as tf
import numpy as np
from typing import Dict, Any

class ImprovedEntityEmbeddingFilling(tf.keras.layers.Layer):
    """æ”¹è¿›çš„user_propernounå¡«å……ç­–ç•¥"""
    
    def __init__(self, config: Dict[str, Any], **kwargs):
        super().__init__(**kwargs)
        self.config = config
        self.noise_scale = config.get('noise_scale', 0.1)
        self.embedding_dim = config.get('embedding_dim', 16)
        
        # è¿™äº›å°†åœ¨è®­ç»ƒæ—¶é€šè¿‡ç»Ÿè®¡è®¡ç®—å¾—å‡º
        self.mean_embedding = None
        self.std_embedding = None
        
    def build(self, input_shape):
        super().build(input_shape)
        
        # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡ï¼ˆå®é™…åº”è¯¥ä»è®­ç»ƒæ•°æ®è®¡ç®—ï¼‰
        # è¿™é‡Œç”¨é»˜è®¤å€¼ï¼Œå®é™…å®ç°æ—¶éœ€è¦ä»é¢„è®¡ç®—çš„ç»Ÿè®¡æ–‡ä»¶åŠ è½½
        self.mean_embedding = tf.Variable(
            tf.zeros([self.embedding_dim]), 
            trainable=False, 
            name='propernoun_mean'
        )
        self.std_embedding = tf.Variable(
            tf.ones([self.embedding_dim]) * 0.1, 
            trainable=False, 
            name='propernoun_std'
        )
    
    def call(self, inputs, training=None):
        """
        å¯¹äºç¼ºå¤±çš„user_propernounï¼Œä½¿ç”¨æ”¹è¿›çš„å¡«å……ç­–ç•¥
        """
        # æ£€æµ‹ç¼ºå¤±å€¼ï¼ˆå‡è®¾ç¼ºå¤±å€¼å·²ç»è¢«æ ‡è®°ï¼‰
        is_missing = tf.reduce_all(tf.equal(inputs, 0.0), axis=-1, keepdims=True)
        
        # ç”Ÿæˆæ”¹è¿›çš„å¡«å……å€¼
        if training:
            # è®­ç»ƒæ—¶æ·»åŠ å™ªéŸ³
            noise = tf.random.normal(
                tf.shape(inputs), 
                mean=0.0, 
                stddev=self.noise_scale
            ) * self.std_embedding
            filled_values = self.mean_embedding + noise
        else:
            # æ¨ç†æ—¶ä½¿ç”¨å¹³å‡å€¼
            filled_values = tf.tile(
                tf.expand_dims(self.mean_embedding, 0),
                [tf.shape(inputs)[0], 1]
            )
        
        # æ¡ä»¶å¡«å……ï¼šç¼ºå¤±æ—¶ç”¨æ–°å€¼ï¼Œå¦åˆ™ä¿æŒåŸå€¼
        outputs = tf.where(is_missing, filled_values, inputs)
        
        return outputs
    
    def set_statistics(self, mean_emb: np.ndarray, std_emb: np.ndarray):
        """è®¾ç½®ç»Ÿè®¡é‡ï¼ˆåœ¨è®­ç»ƒå‰è°ƒç”¨ï¼‰"""
        self.mean_embedding.assign(mean_emb)
        self.std_embedding.assign(std_emb)
```

#### 2. æ›´æ–°å¤„ç†å™¨æ³¨å†Œ

åœ¨ `src/models/deep/processors/__init__.py` ä¸­æ·»åŠ ï¼š

```python
from src.models.deep.processors.improved_filling import ImprovedEntityEmbeddingFilling

__all__ = ['CustomFillNaString', 'ImprovedEntityEmbeddingFilling']
```

### ç¬¬äºŒé˜¶æ®µï¼šä¿®æ”¹é…ç½®æ–‡ä»¶

#### ä¿®æ”¹ `config/feat.yml`

å°† `user_propernoun_emb` çš„é…ç½®ä¿®æ”¹ä¸ºï¼š

```yaml
- feat_name: user_propernoun_emb
  feat_type: SparseFeature
  operations:
    - col_in: user_propernoun
      col_out: user_propernoun
      func_name: FillNaString
      func_parameters:
        fill_value: "NULL#0"
    - col_in: user_propernoun
      col_out: user_propernoun_raw
      func_name: EntityOnlyEmbedding
      func_parameters:
        first_sep: "|"
        second_sep: "#"
        padding_value: "NULL"
        max_length: 10
        embedding_dim: 16
        vocab_size: 3000
        pooling: "mean"
    - col_in: user_propernoun_raw  
      col_out: user_propernoun_emb
      func_name: ImprovedEntityEmbeddingFilling
      func_parameters:
        noise_scale: 0.1
        embedding_dim: 16
```

### ç¬¬ä¸‰é˜¶æ®µï¼šé¢„è®¡ç®—ç»Ÿè®¡é‡

#### åˆ›å»ºç»Ÿè®¡é‡è®¡ç®—è„šæœ¬

åˆ›å»º `scripts/compute_propernoun_stats.py`ï¼š

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import numpy as np
import json
from typing import Dict, List

def extract_propernoun_embedding(propernoun_str: str) -> np.ndarray:
    """ä»propernounå­—ç¬¦ä¸²æå–embedding"""
    if pd.isna(propernoun_str) or propernoun_str == "NULL#0":
        return None
        
    try:
        entities_scores = []
        for item in propernoun_str.split('|'):
            parts = item.split('#')
            if len(parts) == 2:
                entity = parts[0].strip().lower()
                score = float(parts[1])
                entities_scores.append((entity, score))
        
        if not entities_scores:
            return None
        
        # æ¨¡æ‹ŸEntityOnlyEmbeddingçš„å¤„ç†é€»è¾‘
        embedding = np.zeros(16)
        for entity, score in entities_scores:
            entity_hash = abs(hash(entity)) % 16
            embedding[entity_hash] += score
        
        # å½’ä¸€åŒ–
        if np.linalg.norm(embedding) > 0:
            embedding = embedding / np.linalg.norm(embedding)
            return embedding
            
        return None
    except:
        return None

def compute_propernoun_statistics(data_path: str, output_path: str):
    """è®¡ç®—user_propernounçš„ç»Ÿè®¡é‡"""
    
    # åŠ è½½æ•°æ®
    df = pd.read_csv(data_path)
    
    # æå–æ‰€æœ‰æœ‰æ•ˆçš„embedding
    embeddings = []
    for propernoun in df['user_propernoun'].dropna():
        emb = extract_propernoun_embedding(propernoun)
        if emb is not None:
            embeddings.append(emb)
    
    if not embeddings:
        raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„propernoun embedding")
    
    embeddings = np.array(embeddings)
    
    # è®¡ç®—ç»Ÿè®¡é‡
    mean_emb = np.mean(embeddings, axis=0)
    std_emb = np.std(embeddings, axis=0)
    
    # é¿å…æ ‡å‡†å·®ä¸º0
    std_emb = np.maximum(std_emb, 0.01)
    
    # ä¿å­˜ç»Ÿè®¡é‡
    stats = {
        'mean_embedding': mean_emb.tolist(),
        'std_embedding': std_emb.tolist(),
        'num_samples': len(embeddings),
        'embedding_dim': len(mean_emb)
    }
    
    with open(output_path, 'w') as f:
        json.dump(stats, f, indent=2)
    
    print(f"âœ… ç»Ÿè®¡é‡å·²ä¿å­˜åˆ° {output_path}")
    print(f"   æ ·æœ¬æ•°: {len(embeddings)}")
    print(f"   å¹³å‡å€¼æ¨¡é•¿: {np.linalg.norm(mean_emb):.4f}")
    print(f"   å¹³å‡æ ‡å‡†å·®: {np.mean(std_emb):.4f}")

if __name__ == "__main__":
    compute_propernoun_statistics(
        "data/train/20250520.csv",
        "config/propernoun_stats.json"
    )
```

### ç¬¬å››é˜¶æ®µï¼šä¿®æ”¹ç‰¹å¾ç®¡é“

#### æ›´æ–° `src/models/deep/feature_pipeline.py`

åœ¨ `_init_processor_dicts` æ–¹æ³•ä¸­æ·»åŠ ï¼š

```python
def _init_processor_dicts(self):
    """åˆå§‹åŒ–ç‰¹å¾å¤„ç†å™¨å­—å…¸"""
    # å¯¼å…¥æ”¹è¿›çš„å¡«å……å¤„ç†å™¨
    from src.models.deep.processors.improved_filling import ImprovedEntityEmbeddingFilling
    
    custom_processors = {
        "CustomFillNaString": CustomFillNaString,
        "ImprovedEntityEmbeddingFilling": ImprovedEntityEmbeddingFilling
    }
    
    # åˆå¹¶å¤„ç†å™¨å­—å…¸
    self.single_processor_dict = {**SINGLE_PROCESSOR_DICT, **custom_processors}
    self.cross_processor_dict = CROSS_PROCESSOR_DICT
```

åœ¨ `_create_processor` æ–¹æ³•ä¸­æ·»åŠ ç‰¹æ®Šå¤„ç†ï¼š

```python
def _create_processor(self, operation: Dict[str, Any], pipeline: Dict[str, Any]) -> Optional[tf.keras.layers.Layer]:
    """åˆ›å»ºå•ä¸ªå¤„ç†å™¨"""
    func_name = operation['func_name']
    func_parameters = operation.get('func_parameters', {})
    
    # ... å…¶ä»–å¤„ç†é€»è¾‘ ...
    
    # ç‰¹æ®Šå¤„ç†æ”¹è¿›çš„å¡«å……å¤„ç†å™¨
    elif func_name == 'ImprovedEntityEmbeddingFilling':
        return self._create_improved_filling_processor(func_parameters)
    
    # ... å…¶ä»–å¤„ç†é€»è¾‘ ...

def _create_improved_filling_processor(self, parameters: Dict[str, Any]) -> tf.keras.layers.Layer:
    """åˆ›å»ºæ”¹è¿›çš„å¡«å……å¤„ç†å™¨"""
    ImprovedEntityEmbeddingFilling = self.single_processor_dict['ImprovedEntityEmbeddingFilling']
    
    config = {}
    for key, value in parameters.items():
        config[key] = value
    
    return ImprovedEntityEmbeddingFilling(config=config)
```

## ğŸ“‹ å®æ–½æ­¥éª¤

### Day 1: å‡†å¤‡å·¥ä½œ
1. âœ… è¿è¡Œç»Ÿè®¡é‡è®¡ç®—è„šæœ¬
2. âœ… åˆ›å»ºæ”¹è¿›çš„å¡«å……å¤„ç†å™¨  
3. âœ… æ›´æ–°å¤„ç†å™¨æ³¨å†Œ

### Day 2: é…ç½®ä¿®æ”¹
1. âœ… ä¿®æ”¹ `config/feat.yml` é…ç½®
2. âœ… æ›´æ–°ç‰¹å¾ç®¡é“æ„å»ºå™¨
3. âœ… æµ‹è¯•æ–°é…ç½®åŠ è½½

### Day 3: æ¨¡å‹è®­ç»ƒéªŒè¯
1. âœ… ä½¿ç”¨æ–°é…ç½®è®­ç»ƒæ¨¡å‹
2. âœ… å¯¹æ¯”æ–°æ—§æ¨¡å‹AUC
3. âœ… åˆ†æç‰¹å¾é‡è¦æ€§å˜åŒ–

### Day 4: å…¬å¹³æ€§è¯„ä¼°
1. âœ… åˆ†å±‚è¯„ä¼°æœ‰/æ— propernounç”¨æˆ·
2. âœ… æ–°ç”¨æˆ·å†·å¯åŠ¨æµ‹è¯•
3. âœ… A/Bæµ‹è¯•å‡†å¤‡

## ğŸ“Š é¢„æœŸæ•ˆæœ

### é‡åŒ–æŒ‡æ ‡
- **æ•´ä½“AUC**: é¢„æœŸä¿æŒåœ¨0.82ä»¥ä¸Š
- **å…¬å¹³æ€§**: æœ‰/æ— propernounç”¨æˆ·AUCå·®å¼‚ < 0.05  
- **æ–°ç”¨æˆ·å‹å¥½æ€§**: å†·å¯åŠ¨AUCæå‡10-20%

### å®šæ€§æ”¹å–„
- âœ… å‡å°‘æ•°æ®æ³„éœ²é£é™©
- âœ… æé«˜æ¨¡å‹å¯è§£é‡Šæ€§  
- âœ… æ”¹å–„æ–°ç”¨æˆ·ä½“éªŒ
- âœ… æ”¯æŒæ›´å¥½çš„äº§å“å†³ç­–

## ğŸš å‚æ•°è°ƒä¼˜æŒ‡å—

### å…³é”®å‚æ•°
- **noise_scale**: å™ªéŸ³å¼ºåº¦ï¼Œæ¨èèŒƒå›´ [0.05, 0.2]
  - å¤ªå°ï¼šä»æœ‰ç³»ç»Ÿæ€§å·®å¼‚
  - å¤ªå¤§ï¼šå½±å“é¢„æµ‹å‡†ç¡®æ€§

### è°ƒä¼˜ç­–ç•¥
1. ä» `noise_scale=0.1` å¼€å§‹
2. é€šè¿‡éªŒè¯é›†AUCå’Œå…¬å¹³æ€§æŒ‡æ ‡è°ƒä¼˜
3. ç›‘æ§è®­ç»ƒç¨³å®šæ€§

## ğŸ” ç›‘æ§æŒ‡æ ‡

### æ¨¡å‹æ€§èƒ½
- è®­ç»ƒ/éªŒè¯ AUC
- æŸå¤±å‡½æ•°æ”¶æ•›æ€§
- ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ

### å…¬å¹³æ€§æŒ‡æ ‡  
- æœ‰/æ— propernounç”¨æˆ·AUCå·®å¼‚
- ä¸åŒç”¨æˆ·ç¾¤ä½“çš„é¢„æµ‹å‡†ç¡®æ€§
- æ–°ç”¨æˆ·vsè€ç”¨æˆ·è¡¨ç°å¯¹æ¯”

### ä¸šåŠ¡æŒ‡æ ‡
- æ¨é€ç‚¹å‡»ç‡
- ç”¨æˆ·ç•™å­˜ç‡
- é•¿æœŸç”¨æˆ·æ´»è·ƒåº¦

## ğŸš€ é«˜çº§ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

### 1. è‡ªé€‚åº”å™ªéŸ³
æ ¹æ®ç”¨æˆ·æ´»è·ƒåº¦åŠ¨æ€è°ƒæ•´å™ªéŸ³å¼ºåº¦ï¼š

```python
def adaptive_noise_scale(user_activity_level):
    """æ ¹æ®ç”¨æˆ·æ´»è·ƒåº¦è°ƒæ•´å™ªéŸ³"""
    if user_activity_level < 5:
        return 0.15  # æ–°ç”¨æˆ·æ›´å¤šå™ªéŸ³
    elif user_activity_level < 20:
        return 0.1   # ä¸­ç­‰æ´»è·ƒç”¨æˆ·
    else:
        return 0.05  # é«˜æ´»è·ƒç”¨æˆ·æ›´å°‘å™ªéŸ³
```

### 2. å¤šå±‚çº§å¡«å……
ä¸ºä¸åŒç±»å‹çš„ç¼ºå¤±ç”¨æˆ·ä½¿ç”¨ä¸åŒçš„å¡«å……ç­–ç•¥ï¼š

```python
# å®Œå…¨æ–°ç”¨æˆ·ï¼šä½¿ç”¨å…¨å±€å¹³å‡
# æœ‰å†å²ä½†æ— propernounï¼šä½¿ç”¨ç›¸ä¼¼ç”¨æˆ·å¹³å‡  
# ç³»ç»Ÿå¼‚å¸¸ç¼ºå¤±ï¼šä½¿ç”¨ç”¨æˆ·å†å²å¹³å‡
```

## ğŸ’¡ æ€»ç»“

è¿™ä¸ªè§£å†³æ–¹æ¡ˆçš„æ ¸å¿ƒä»·å€¼åœ¨äºï¼š

1. **ç®€å•é«˜æ•ˆ** - æ— éœ€æ”¹å˜æ¨¡å‹æ¶æ„ï¼Œåªä¿®æ”¹æ•°æ®é¢„å¤„ç†
2. **æ•ˆæœæ˜¾è‘—** - æ˜¾è‘—æ”¹å–„å…¬å¹³æ€§ï¼Œä¿æŒé¢„æµ‹å‡†ç¡®æ€§
3. **é£é™©å¯æ§** - å‚æ•°å¯è°ƒï¼Œæ•ˆæœå¯ç›‘æ§
4. **æ˜“äºå®æ–½** - åŸºäºç°æœ‰pipelineï¼Œæ”¹åŠ¨æœ€å°

é€šè¿‡æ”¹è¿›embeddingå¡«å……ç­–ç•¥ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¿æŒ`user_propernoun`è¯­ä¹‰ä»·å€¼çš„åŒæ—¶ï¼Œå‡å°‘å…¶ä½œä¸ºæ´»è·ƒåº¦è¯†åˆ«å™¨çš„ä¸å…¬å¹³ä¼˜åŠ¿ï¼Œä»è€Œæ„å»ºä¸€ä¸ªæ›´åŠ å…¬å¹³å’Œå¯é çš„æ¨èç³»ç»Ÿã€‚

---

*è¯¥æ–¹æ¡ˆåŸºäºå¯¹10,000æ ·æœ¬çš„æ·±åº¦æ•°æ®åˆ†æï¼ŒåŒ…å«4,440ä¸ªç”¨æˆ·çš„è¡Œä¸ºæ¨¡å¼ç ”ç©¶ã€‚å®æ–½å‰å»ºè®®è¿›è¡Œå°è§„æ¨¡A/Bæµ‹è¯•éªŒè¯æ•ˆæœã€‚* 